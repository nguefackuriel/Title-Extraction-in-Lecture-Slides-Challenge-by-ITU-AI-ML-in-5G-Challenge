# Title-Extraction-in-Lecture-Slides-Challenge-by-ITU-AI-ML-in-5G-Challenge

This is a Zindi Competition in which I participated. My Solution ranked 6th out of 26 participants.

I used DeepLabV3 model with a Resnext50 Backbone trained with 5 epochs.

Below is the description of the competition.

Description
YouTube’s “Video Chapter” feature segments a video into sections marked by timestamps so that the user can easily navigate to the part of the video which is of most interest. This can be done by clicking or pressing the chapter marker, or by selecting the timestamp in the video description.

In this problem statement we want to take this feature further. In webinars where speakers present slides, participants of the problem statement are asked to create the best AI model which annotates slides by identifying (apparent) titles in frames extracted from presentations.

Recordings of 100 “AI for Good” webinars were sourced to assemble a diverse collection of more than 140 video presentations made by members of the scientific community, entrepreneurs, and standardization experts. These were then segmented into frames containing the slides with titles.

An automated slide annotation in videos will improve accessibility of lecture-like content and enable better analytics.

The link to the competition is [title-extraction-in-lecture-slides-challenge](https://zindi.africa/competitions/title-extraction-in-lecture-slides-challenge)
